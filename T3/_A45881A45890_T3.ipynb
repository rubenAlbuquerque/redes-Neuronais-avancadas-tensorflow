{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "import os\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    fig = plt.figure(figsize=(6.5, 6.5))\n",
    "    plt.imshow(cm, interpolation='none', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, ha='right')\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    # return fig\n",
    "\n",
    "\n",
    "def log(msg):\n",
    "    print(msg, '\\n')\n",
    "\n",
    "\n",
    "def createFolders():\n",
    "    for breed in list(classDic.keys()):\n",
    "        # Breeds\n",
    "        trainPath = os.path.join('./breeds/train/' + breed)\n",
    "        if not os.path.exists(trainPath):\n",
    "            os.mkdir('./breeds/train/' + breed)\n",
    "\n",
    "        testPath = os.path.join('./breeds/test/' + breed)\n",
    "        if not os.path.exists(testPath):\n",
    "            os.mkdir('./breeds/test/' + breed)\n",
    "\n",
    "        # Dogs\n",
    "        trainPath = os.path.join('./species/train/dog')\n",
    "        if not os.path.exists(trainPath):\n",
    "            os.mkdir('./species/train/dog')\n",
    "\n",
    "        testPath = os.path.join('./species/test/dog')\n",
    "        if not os.path.exists(testPath):\n",
    "            os.mkdir('./species/test/dog')\n",
    "\n",
    "        # Cats\n",
    "        trainPath = os.path.join('./species/train/cat')\n",
    "        if not os.path.exists(trainPath):\n",
    "            os.mkdir('./species/train/cat')\n",
    "\n",
    "        testPath = os.path.join('./species/test/cat')\n",
    "        if not os.path.exists(testPath):\n",
    "            os.mkdir('./species/test/cat')\n",
    "\n",
    "\n",
    "def splitBreeds():\n",
    "    for imgName in list(filesDic.keys()):\n",
    "        img = keras.preprocessing.image.load_img('images/' + imgName)\n",
    "        foldTrain = filesDic.get(imgName).get('foldTrain')\n",
    "\n",
    "        keras.preprocessing.image.save_img(\n",
    "            './breeds/' + ('train/' if foldTrain else 'test/') + filesDic.get(imgName).get('breed') + '/' + imgName, img)\n",
    "\n",
    "\n",
    "def splitSpecies():\n",
    "    for imgName in list(filesDic.keys()):\n",
    "        img = keras.preprocessing.image.load_img('images/' + imgName)\n",
    "        foldTrain = filesDic.get(imgName).get('foldTrain')\n",
    "\n",
    "        keras.preprocessing.image.save_img(\n",
    "            './species/' + ('train/' if foldTrain else 'test/') + filesDic.get(imgName).get('species') + '/' + imgName, img)\n",
    "\n",
    "\n",
    "D = dict(pickle.load(open('Oxford-IIIT-Pet_Dics.p', 'rb')))\n",
    "# log(D)\n",
    "imageNum = 7390\n",
    "\n",
    "DKeys = list(D.keys())\n",
    "# log(DKeys)\n",
    "\n",
    "classDic = dict(D.get('classDic'))\n",
    "# log(classDic)\n",
    "\n",
    "filesDic = dict(D.get('filesDic'))\n",
    "# log(list(filesDic.keys()))\n",
    "filesDicValues = list(filesDic.values())\n",
    "# log(filesDicValues[-1:])\n",
    "\n",
    "# createFolders()\n",
    "# splitBreeds()\n",
    "# splitSpecies()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN network from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speciesCnn = models.Sequential()\n",
    "\n",
    "speciesCnn.add(layers.Conv2D(6, (5, 5), activation='relu',\n",
    "                             input_shape=(224, 224, 3), padding=\"same\"))\n",
    "speciesCnn.add(layers.AveragePooling2D((2, 2)))\n",
    "speciesCnn.add(layers.Conv2D(16, (5, 5), activation='relu'))\n",
    "speciesCnn.add(layers.AveragePooling2D((2, 2)))\n",
    "speciesCnn.add(layers.Conv2D(120, (1, 1), activation='relu'))\n",
    "speciesCnn.add(layers.Flatten())\n",
    "speciesCnn.add(layers.Dense(64, activation='relu'))\n",
    "speciesCnn.add(layers.Dense(2, activation='softmax'))  # 2 species\n",
    "\n",
    "speciesCnn.summary()\n",
    "\n",
    "speciesCnn.compile(optimizer=\"nadam\",\n",
    "                   loss=\"categorical_crossentropy\",\n",
    "                   metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breedsCnn = models.Sequential()\n",
    "\n",
    "breedsCnn.add(layers.Conv2D(6, (5, 5), activation='relu',\n",
    "                            input_shape=(224, 224, 3), padding=\"same\"))\n",
    "breedsCnn.add(layers.AveragePooling2D((2, 2)))\n",
    "breedsCnn.add(layers.Conv2D(16, (5, 5), activation='relu'))\n",
    "breedsCnn.add(layers.AveragePooling2D((2, 2)))\n",
    "breedsCnn.add(layers.Conv2D(120, (1, 1), activation='relu'))\n",
    "breedsCnn.add(layers.Flatten())\n",
    "breedsCnn.add(layers.Dense(64, activation='relu'))\n",
    "breedsCnn.add(layers.Dense(37, activation='softmax'))  # 37 breeds\n",
    "\n",
    "breedsCnn.summary()\n",
    "\n",
    "breedsCnn.compile(optimizer=\"nadam\",\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using input size of 224x224 because it seems a good shape for the overall images and it's to be compatible with the mobileNet network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "\n",
    "mn2 = MobileNetV2(weights='imagenet',\n",
    "                  input_shape=(224, 224, 3))\n",
    "\n",
    "mn2.trainable = False\n",
    "\n",
    "# mn2.summary()\n",
    "\n",
    "breedsMn2Cnn = models.Sequential()\n",
    "breedsMn2Cnn.add(mn2)\n",
    "breedsMn2Cnn.add(layers.Flatten())\n",
    "breedsMn2Cnn.add(layers.Dense(37, activation='softmax'))  # 37 breeds\n",
    "\n",
    "breedsMn2Cnn.summary()\n",
    "\n",
    "breedsMn2Cnn.compile(optimizer=\"nadam\",\n",
    "                     loss=\"categorical_crossentropy\",\n",
    "                     metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have chosen the mobileNetV2 because it's a network that has 3.5M parameters and makes it quick for us to train, compared to other networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator with and without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "breedsDir = './breeds/'\n",
    "\n",
    "breedsGen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "breedsGenAug = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                  rotation_range=30,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode=\"nearest\")\n",
    "\n",
    "breedsTrainGen = breedsGen.flow_from_directory(directory=breedsDir + \"train/\",\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               batch_size=32)\n",
    "\n",
    "breedsTrainGenAug = breedsGenAug.flow_from_directory(directory=breedsDir + \"train/\",\n",
    "                                                     target_size=(224, 224),\n",
    "                                                     class_mode=\"categorical\",\n",
    "                                                     batch_size=32)\n",
    "\n",
    "breedsTestGen = breedsGen.flow_from_directory(directory=breedsDir + \"test/\",\n",
    "                                              target_size=(224, 224),\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              batch_size=32)\n",
    "\n",
    "speciesDir = './species/'\n",
    "\n",
    "speciesGen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "speciesGenAug = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=30,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode=\"nearest\")\n",
    "\n",
    "speciesTrainGen = speciesGen.flow_from_directory(directory=speciesDir + \"train/\",\n",
    "                                                 target_size=(224, 224),\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 batch_size=32)\n",
    "\n",
    "speciesTrainGenAug = speciesGenAug.flow_from_directory(directory=speciesDir + \"train/\",\n",
    "                                                       target_size=(224, 224),\n",
    "                                                       class_mode=\"categorical\",\n",
    "                                                       batch_size=32)\n",
    "\n",
    "speciesTestGen = speciesGen.flow_from_directory(directory=speciesDir + \"test/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we don't augment the data for the test set\n",
    "\n",
    "If we were to use validation data, we wouldn't use data augmentation either\n",
    "\n",
    "Loading the images with the Keras image generators, specifying a predefined dimension (height and width), we introduce a new problem: The fact that we are resizing the images, results in distortions that vary with the original size of the image. To deal with such a problem, there are techniques available online to minimize the distortion and noise originated by the image resizing. Most of those techniques consist of gathering images in batches with similar dimensions and creatign a preprocessing function from scratch that handles those different batches. The whole process is explained in this link: https://medium.com/softmax/keras-data-generator-for-images-of-different-dimensions-9ff82f6fab03\n",
    "\n",
    "Due to shortage of time, we weren't able to explore those possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary (Species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = speciesCnn.fit(speciesTrainGen,\n",
    "                     epochs=epochs,\n",
    "                     validation_data=speciesTestGen)\n",
    "\n",
    "h = log.history\n",
    "plt.plot(h[\"loss\"], label='Loss')\n",
    "plt.plot(h[\"accuracy\"], label='Accuracy')\n",
    "plt.plot(h[\"val_loss\"], label='Val Loss')\n",
    "plt.plot(h[\"val_accuracy\"], label='Val Acurracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted = speciesCnn.predict(speciesTestGen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.argmax(predicted, axis=1)\n",
    "\n",
    "print('Number of erros:', np.sum(p != speciesTestGen.classes))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(p, speciesTestGen.classes),\n",
    "                      classes=speciesTestGen.class_indices.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = speciesCnn.fit(speciesTrainGenAug,\n",
    "                     epochs=epochs,\n",
    "                     validation_data=speciesTestGen)\n",
    "\n",
    "h = log.history\n",
    "plt.plot(h[\"loss\"], label='Loss')\n",
    "plt.plot(h[\"accuracy\"], label='Accuracy')\n",
    "plt.plot(h[\"val_loss\"], label='Val Loss')\n",
    "plt.plot(h[\"val_accuracy\"], label='Val Acurracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted = speciesCnn.predict(speciesTestGen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.argmax(predicted, axis=1)\n",
    "\n",
    "print('Number of erros:', np.sum(p != speciesTestGen.classes))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(p, speciesTestGen.classes),\n",
    "                      classes=speciesTestGen.class_indices.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class (Breeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = breedsCnn.fit(breedsTrainGen,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=breedsTestGen)\n",
    "\n",
    "h = log.history\n",
    "plt.plot(h[\"loss\"], label='Loss')\n",
    "plt.plot(h[\"accuracy\"], label='Accuracy')\n",
    "plt.plot(h[\"val_loss\"], label='Val Loss')\n",
    "plt.plot(h[\"val_accuracy\"], label='Val Acurracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted = breedsCnn.predict(breedsTestGen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.argmax(predicted, axis=1)\n",
    "\n",
    "print('Number of erros:', np.sum(p != breedsTestGen.classes))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(p, breedsTestGen.classes),\n",
    "                      classes=breedsTestGen.class_indices.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = breedsMn2Cnn.fit(breedsTrainGen,\n",
    "                       epochs=epochs,\n",
    "                       validation_data=breedsTestGen)\n",
    "\n",
    "h = log.history\n",
    "plt.plot(h[\"loss\"], label='Loss')\n",
    "plt.plot(h[\"accuracy\"], label='Accuracy')\n",
    "plt.plot(h[\"val_loss\"], label='Val Loss')\n",
    "plt.plot(h[\"val_accuracy\"], label='Val Acurracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted = breedsMn2Cnn.predict(breedsTestGen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.argmax(predicted, axis=1)\n",
    "\n",
    "print('Number of erros:', np.sum(p != breedsTestGen.classes))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(p, breedsTestGen.classes),\n",
    "                      classes=breedsTestGen.class_indices.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class (Breeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = breedsCnn.fit(breedsTrainGenAug,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=breedsTestGen)\n",
    "\n",
    "h = log.history\n",
    "plt.plot(h[\"loss\"], label='Loss')\n",
    "plt.plot(h[\"accuracy\"], label='Accuracy')\n",
    "plt.plot(h[\"val_loss\"], label='Val Loss')\n",
    "plt.plot(h[\"val_accuracy\"], label='Val Acurracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted = breedsCnn.predict(breedsTestGen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.argmax(predicted, axis=1)\n",
    "\n",
    "print('Number of erros:', np.sum(p != breedsTestGen.classes))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(p, breedsTestGen.classes),\n",
    "                      classes=breedsTestGen.class_indices.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = breedsMn2Cnn.fit(breedsTrainGenAug,\n",
    "                       epochs=epochs,\n",
    "                       validation_data=breedsTestGen)\n",
    "\n",
    "h = log.history\n",
    "plt.plot(h[\"loss\"], label='Loss')\n",
    "plt.plot(h[\"accuracy\"], label='Accuracy')\n",
    "plt.plot(h[\"val_loss\"], label='Val Loss')\n",
    "plt.plot(h[\"val_accuracy\"], label='Val Acurracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted = breedsMn2Cnn.predict(breedsTestGen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.argmax(predicted, axis=1)\n",
    "\n",
    "print('Number of erros:', np.sum(p != breedsTestGen.classes))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(p, breedsTestGen.classes),\n",
    "                      classes=breedsTestGen.class_indices.keys())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b5be1fd1de7b40782a9e00e64e3cbb4863fd6c2414af64edfcd9ccb8133f2c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
